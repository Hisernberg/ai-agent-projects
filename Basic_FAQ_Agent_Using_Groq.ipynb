{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hisernberg/ai-agent-projects/blob/main/Basic_FAQ_Agent_Using_Groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain langchain-community langchain-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMy_60H9l6dd",
        "outputId": "923997d4-9c24-4f6c-9299-533ff27e6d32",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.47)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq #Changed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QdZnK4fQ-MQ",
        "outputId": "b197feec-ed38-4a6e-81da-8a30780d12a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/124.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OMgRh6AUeU-6",
        "outputId": "20dd1d35-b0c9-4335-89e0-a50b9523bdf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('groq-apikey') #Changed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import openai\n",
        "from langchain_groq import ChatGroq#Changed\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Set up OpenAI API key\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq-apikey')  # Replace with your API key #Changed\n",
        "\n",
        "# Sample FAQ data on agents and their benefits\n",
        "faq_data = [\n",
        "    {\"question\": \"What is an AI agent?\", \"answer\": \"An AI agent is a system that can autonomously perform tasks based on inputs and learned knowledge.\"},\n",
        "    {\"question\": \"How can AI agents improve efficiency?\", \"answer\": \"AI agents can automate repetitive tasks, streamline decision-making, and enhance customer support with accurate responses.\"},\n",
        "    {\"question\": \"What industries benefit most from AI agents?\", \"answer\": \"Industries like healthcare, e-commerce, finance, and customer support heavily benefit from AI agents.\"},\n",
        "    {\"question\": \"Are AI agents customizable?\", \"answer\": \"Yes, AI agents can be trained with specific data and prompts to suit various use cases.\"}\n",
        "]\n",
        "\n",
        "# Initialize the GPT-4o mini model\n",
        "chat_model = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) #Changed\n",
        "\n",
        "# Create a template for chatbot responses\n",
        "faq_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"You are an AI chatbot. Answer this question based on the provided FAQ data:\\n{faq_data}\\nQuestion: {question}\"\n",
        ")\n",
        "\n",
        "# Create a chain for handling chatbot interactions\n",
        "faq_chain = LLMChain(\n",
        "    prompt=faq_template,\n",
        "    llm=chat_model\n",
        ")\n",
        "\n",
        "# Function to handle user queries\n",
        "def chatbot():\n",
        "    print(\"Welcome to the AI FAQ Chatbot! Ask me about agents and their benefits. Type 'exit' to stop.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        response = faq_chain.run({\"question\": user_input, \"faq_data\": faq_data})\n",
        "        print(\"Bot:\", response)\n",
        "\n",
        "# Run the chatbot in Colab\n",
        "display(chatbot())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgE7tjDgla-U",
        "outputId": "f3caa177-a091-43b9-99c8-7a37115eb798"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the AI FAQ Chatbot! Ask me about agents and their benefits. Type 'exit' to stop.\n",
            "Bot: An AI agent is a system that can autonomously perform tasks based on inputs and learned knowledge.\n",
            "Bot: It seems like the provided FAQ data does not directly answer the question \"What is the economical benefit of AI Agent?\" However, we can infer some information from the existing data.\n",
            "\n",
            "The FAQ mentions that AI agents can \"automate repetitive tasks, streamline decision-making, and enhance customer support with accurate responses\" which can lead to improved efficiency. This can result in cost savings and productivity gains, which are typically considered economical benefits.\n",
            "\n",
            "However, a more direct answer to your question would be: Unfortunately, the provided FAQ data does not explicitly mention the economical benefit of AI Agents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI FAQ Chatbot Code Explanation\n",
        "![Code explanation in flow chart](https://lh3.googleusercontent.com/fife/ALs6j_EDrqGwgruo2lGaqFYMCcp495dVJbKvHpHhdGjGkA35ZOochkI6TAI6_1h23CVh06hVz4nKeI-KCYYrC8yXZSczAPeHhSWQfHMbnjySar_678_V_kw5g15yP7RZh_JiePWdX0rPqNifX7GzbjAGyKDMpx1XloX4e3tu8n-bblpf7IJOsJrCqaOr-5IL6k8zGNJ8wByachzpTXn1DQI2W9dGH_Y53R2Jxrgb8Hk1KxPIhHojJ58LVpqPDz_G37b6E_Gp-ZQXpxCRnqJI_aU8T1GrAK5g6P4Kce0vWUoBjd6jMr3M680wTNnc60rPnoV40WUp9SsNUPEzbgam6-Zvdtm9tIvCxjpwIqw0k_XGkE5-9fw_P8TEJzoKsQRF76gbGrNbMv2JVZqiO_0sfMSFH_sDMWolnVfvawxjOl-IawslgHC_vzp4RCFnR8jnTvK7gjaUU9KbAlIegprgJXl_K_ANUblSQ53f0f1H5kORrzdxt-vLG-i5c0ODLzzdVpr7TRheEWYhww26iHtNAkEIeT1gant-molFbOyRGmvofiAw5-4nltfMpeDAymEoKy2iPLIiWP3ZQylN907RRZ2QNhJNrBPrlV3o9qXf8bdkJCTwcr1rwa60N4ZOKgK5LsKzorkOyof6x3yCsJLCnA82zec-_4i3dDTNU5wuOPeVv1iSvTYETTBoUeOmZrPMsmNawL9yTa9PYBaTmfCU7fhsV1A2JAv97ZpEAABXNNKSNu1474_O8N-s-XZh9tHOcnwMjZWYWxmHMRyow0mJVVMvl5pwDlkadX02KZ-xYKRk1B4pWDm1PQolpc9POBfW0RT6lxyYSxP65-Pg-xyMTEspWyyo3T9gSMQyDaSGZNqMCFp6XhplinnG758ILL-SyzfaQM9jvT_RkQh5YAyZI2uiakOC90KzBJUseRjxdzfyrx9-w-WEGLsGghPa02AeZqobsnkPjnnDGMpInrv1Zz9xWsLRQTcU2yeUj7vRUOvroCFHyONTsdL6E6tJrMFxmT4berLy9AXBhQo3GJwq0YaHML70-3kf3ZHROlh_2UU4JMQoBBVcwo9sdLOLf9AonnPY8LtZ8-d02s98cyHDH2tDthOvGSh9aJ52xFfqlWOyHBsda7J-1R1qHc3wYS04GoGhVESm74o0WNT1K0I5xkb0C7AHX_vQurWB4f_VSU140np1eRpePpl0SdZ9a5xXar22zRyG71PW1o6BFu2gnx79zWqDAq63tKpVTLLw0Lc6lUT7Ed5cFaZr-caXcwOfLt-LMfd0wwWR1TQW0I6GMPcIPgX0P3b0ugkvW9ZYlKvBhH4N003zrDPXu1WZU5PmSNUHtO0CdZKip8RbCT79iPkJ86NrdZ0IizkLChZGTTE83lMLRvRoOXEx7whpVTUi50zDOA9yCXfdh0l8gR8ZessV-qO9Jpg-1lMjxoI9t2gk8P-8yw8kZKhMizL-wW6Q2VWHiLY11arR-y8b7M1e_gw5lE573lyANk_kLYBU15kdPk-UCPTE2Yt0WcLIkzivO4WOr651_kKYjRHHy9fTPnEebhWanBjXoERppF2ngVoGS9M_oMQuZ0nNvyLfeYoah5iLVX-MzPWYBEZ0x2QyzOHeBQ=w2880-h1631)\n",
        "\n",
        "## Step 1: Install Required Libraries\n",
        "- The code installs three key libraries:\n",
        "  - `openai`: For interacting with the OpenAI API.\n",
        "  - `langchain`: To simplify the creation of LLM chains for structured responses.\n",
        "  - `graphviz`: For visualizing the chatbot's flow using diagrams.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 2: Import Necessary Libraries\n",
        "- The required libraries are imported:\n",
        "  - `openai` for API interaction.\n",
        "  - `ChatOpenAI`, `PromptTemplate`, and `LLMChain` from LangChain to build the chatbot's logic.\n",
        "  - `Digraph` from Graphviz for generating the flowchart visualization.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3: Set Up OpenAI API Key\n",
        "- The OpenAI API key is set using the `os` environment variable.\n",
        "- This ensures secure access to GPT-4o for generating chatbot responses.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 4: Define Sample FAQ Data\n",
        "- A sample dataset is defined as a list of dictionaries, each containing:\n",
        "  - **`question`**: The question asked.\n",
        "  - **`answer`**: The corresponding answer.\n",
        "- This dataset helps guide the chatbot's responses.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 5: Initialize the gpt-4o-mini Model\n",
        "- The GPT-4o model is initialized with:\n",
        "  - **`model=\"gpt-4o-mini\"`**: Uses GPT-4o for optimal performance.\n",
        "  - **`temperature=0.7`**: Controls randomness — higher values increase creativity, while lower values make responses more focused.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 6: Create a Prompt Template\n",
        "- The prompt template structures the conversation by:\n",
        "  - Incorporating the FAQ data.\n",
        "  - Formulating questions in a clear format for the model.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 7: Create Chain for Chatbot\n",
        "- An `LLMChain` is created to:\n",
        "  - Process user queries using the chatbot model.\n",
        "  - Combine the template and the GPT-4o model.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 8: Define Chatbot Function\n",
        "- The chatbot function handles the user interaction loop:\n",
        "  - It greets the user.\n",
        "  - Continuously accepts user input until 'exit' is typed.\n",
        "  - It fetches responses from the `faq_chain` using the user's question.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 9: Define Flowchart Generation\n",
        "- The `generate_flowchart` function creates a visual diagram of the code’s flow:\n",
        "  - Nodes represent steps in the code.\n",
        "  - Edges connect these nodes to depict the logical flow.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 10: Run Chatbot and Flowchart\n",
        "- The chatbot function is executed to start user interaction.\n",
        "- The `generate_flowchart()` function produces a `.png` visualization of the chatbot’s logic.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Notes\n",
        "- The chatbot effectively leverages GPT-4o for natural language responses.\n",
        "- The flowchart provides a clear visual guide to the code’s structure.\n"
      ],
      "metadata": {
        "id": "yQL6QP17rStG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SB61PFNRrTaL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}